services:

  # Tailscale Sidecar Configuration
  tailscale-uptime-kuma:
    image: tailscale/tailscale:latest # Image to be used
    container_name: tailscale-uptime-kuma # Name for local container management
    hostname: uptime # Name used within your Tailscale environment
    environment:
      - TS_AUTHKEY=tskey-auth-<ADD-YOUR-AUTH-KEY-HERE>
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_SERVE_CONFIG=/config/serve.json # Tailsacale Serve configuration to expose the web interface on your local Tailnet - remove this line if not required
      - TS_USERSPACE=false
    volumes:
      - ${PWD}/uptime-kuma/config:/config # Config folder used to store Tailscale files - you may need to change the path
      - ${PWD}/uptime-kuma/tailscale-uptime-kuma/state:/var/lib/tailscale # Tailscale requirement - you may need to change the path
      - /dev/net/tun:/dev/net/tun # Network configuration for Tailscale to work
    cap_add:
      - net_admin
      - sys_module
    # If any DNS issues arise, use your preferred DNS provider by uncommenting the config below
    # dns: 
    #   - 1.1.1.1 
    healthcheck:
      test: ["CMD", "tailscale", "status"] # Check if Tailscale is running
      interval: 1m # How often to perform the check
      timeout: 10s # Time to wait for the check to succeed
      retries: 3 # Number of retries before marking as unhealthy
      start_period: 10s # Time to wait before starting health checks
    restart: always

  # uptime-kuma
  uptime-kuma:
    image: louislam/uptime-kuma:latest # Image to be used
    network_mode: service:tailscale-uptime-kuma  # Sidecar configuration to route uptime-kuma through Tailscale
    container_name: uptime-kuma # Name for local container management
    volumes:
      - ${PWD}/uptime-kuma/uptime-kuma-data:/app/data # uptime-kuma data/configuration folder
      - /var/run/docker.sock:/var/run/docker.sock:ro # Read-only access to the docker.sock
    depends_on:
      - tailscale-uptime-kuma
    restart: always